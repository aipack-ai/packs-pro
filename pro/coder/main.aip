# Before All

Here we do the prep work in the "Before All" section in case we need to set `split_file_into_inputs = true`.

This will return inputs, where each input will have `.context_files: string[]`. This way, the input run can operate on multiple files or just get one file in the array (or eventually more than one).

```lua
local p_utils  = require("prompt_utils")
local p_tmpl   = require("prompt_tmpl")
local consts   = require("consts")

-- Dictionary of instructions that will be used by this agent
-- e.g. .file_content_change (for the whole/search_replace/... instructions), 
--      .user_custom (for the git commit)
--      .missing_files (for the missing files)
local instructions  = {}

-- === Check AIPACK Version
if not aip.semver.compare(CTX.AIPACK_VERSION, ">", "0.8.4") then
    local msg = "\nWARNING - This pack requires AIPACK_VERSION 0.8.4 or above, but " .. CTX.AIPACK_VERSION .. " is currently installed"
    msg = msg .. "\n\nACTION  - Update your aipack `cargo install aipack` (to check your aipack version run 'aip -V')"
    print(msg)
    return aip.flow.skip("Wrong aipack version")
end

-- === Init the prompt file if needed
local default_prompt_absolute_dir  = CTX.WORKSPACE_AIPACK_DIR .. "/.prompt/" .. CTX.PACK_IDENTITY
local default_prompt_file_path     = default_prompt_absolute_dir .. "/coder-prompt.md"

local input = inputs and inputs[1] or nil

local prompt_file = p_utils.prep_prompt_file(input, {
    default_prompt_path = default_prompt_file_path
})

-- if path start with "./"
local prompt_file_rel_path = nil
if prompt_file.path:sub(1, 2) == "./" then
    prompt_file_rel_path = prompt_file.path:sub(3)
else
    prompt_file_rel_path = aip.path.diff(prompt_file.path, CTX.WORKSPACE_DIR)
end
local prompt_dir_rel_path  = prompt_file.dir


-- Save the dev plan files only if not present
p_tmpl.init_fixed_files(prompt_dir_rel_path)

-- === Extract data from prompt files
-- Split the prompt into inst and content
local first_part, second_part = p_utils.prep_inst_and_content(prompt_file.content, "====", {content_is_default = false})

-- Clean the second_part
if second_part ~= nil then
    second_part = aip.text.trim(second_part)
    -- now remove the first line block with ">"
    local _note_blocks, remain = aip.text.extract_line_blocks(second_part, {starts_with = ">", extrude = "content", first = 1})
    second_part = aip.text.trim(remain)
    if #second_part == 0 then
        second_part = nil
    end
end

-- Note: For now, we ignore the second part, as this will display what the AI says beside the code it gives. This allows for explanations, but there is no need to put it back in context.

-- === Extract the meta and instruction
local meta, inst = aip.md.extract_meta(first_part)
-- Remove the `> ..` lines
local _line_blocks, inst_content = aip.text.extract_line_blocks(inst,
                                             {starts_with = ">", extrude = "content"})
inst = aip.text.trim(inst_content)

-- === Determine if we should skip
if inst == "" then
    local msg = "Empty instruction. Open & Edit prompt file:\n\n"
    msg = msg .. "➜ " .. prompt_file_rel_path .. "\n\n(And press [r] for Replay)"
    return aip.flow.skip(msg)
end

-- === Extract the eventual md ref
local attachments = nil
if aip.md.extract_refs then -- api from api v0.8.10
    local md_refs = aip.md.extract_refs(inst)

    if #md_refs > 0 then
    attachments = {}
    for _, md_ref in ipairs(md_refs) do
        if md_ref.inline and md_ref.kind == "File" then
            local file_path = prompt_dir_rel_path .. "/" .. md_ref.target;
            file_path = aip.path.resolve(file_path)
            table.insert(attachments, {
                file_source = file_path,
                title       = md_ref.text,
            })
        end
    end
    end
end


-- === Clean legacy file (since 0.2.27)
local legacy_prompt_files_path            = prompt_file.dir .. "/" .. ".cache/prompt_files_path.md"
if aip.path.exists(legacy_prompt_files_path) then 
    aip.file.delete(legacy_prompt_files_path)
end

-- === Prep the cache files
local prompt_files_path            = prompt_file.dir .. "/" .. ".cache/last_prompt_files_path.md"
aip.file.save(prompt_files_path, "")
local ai_responses_for_raw_path    = prompt_file.dir .. "/" .. ".cache/last_ai_responses_for_raw.md"
aip.file.save(ai_responses_for_raw_path, "")
local ai_responses_for_prompt_path = prompt_file.dir .. "/" .. ".cache/last_ai_responses_for_prompt.md"
aip.file.save(ai_responses_for_prompt_path, "")
local last_file_change_fails_report_path = prompt_file.dir .. "/" .. ".cache/last_file_change_fails_report.md"
if aip.path.exists(last_file_change_fails_report_path) then 
    aip.file.delete(last_file_change_fails_report_path)
end

-- === Prep knowledge_refs
local knowledge_refs = nil
if p_utils.is_not_empty(meta.knowledge_globs) then
    knowledge_refs = aip.file.list(meta.knowledge_globs, {base_dir = CTX.WORKSPACE_DIR})
end

-- === Prep context_refs and working_refs
local base_dir = meta.base_dir or ""

local context_refs        = nil
local structure_refs      = nil
local working_refs_list   = nil

if base_dir ~= nil then
    -- Remove the trailing /
    base_dir =  base_dir:gsub("/+$", "")

    -- Prep structure_globs = "**/*.*"
    local structure_globs = nil
    if p_utils.is_not_empty(meta.structure_globs)  then
        structure_refs = aip.file.list(meta.structure_globs, {base_dir = base_dir})
    end

    context_refs = {} -- probably need to be nil to be consistent
    if p_utils.is_not_empty(meta.context_globs)  then
        context_refs = aip.file.list(meta.context_globs, {base_dir = base_dir})
    end

    -- Prep working_refs_list
    if p_utils.is_not_empty(meta.working_globs) then
        working_refs_list = p_utils.compute_working_refs_list(meta.working_globs, base_dir)
        -- OLD WAY
        -- working_refs = aip.file.list(meta.working_globs, {base_dir = base_dir})
    end
else
    print("INFO: No base_dir, update in place.")
end

local write_mode = meta.write_mode or false

local max_files_size_kb = meta.max_files_size_kb or consts.DEFAULT_MAX_FILES_SIZE_KB

-- === Compute include_second_partby default we include second part if not nil
local include_second_part = second_part ~= nil
if write_mode == true then
    -- if write_mode, we do not include second part
    include_second_part = false
end

-- === More logic
print("Prompt file ➜ " .. prompt_file_rel_path)


-- === Defined the explicit cache strategy (for Anthropic)

-- Default false
local cache_pre_prompts = false
local cache_knowledge_files = false
if meta.cache_explicit then 
    cache_pre_prompts = true
    cache_knowledge_files = true
end

-- NOTE: For now, always false. 
local cache_context_files = false
-- if working_refs_list ~= nil then
--     cache_context_files = true
-- end

-- === Compute file_content_mode
-- file_content_mode = "whole" or file_content_mode = "search_replace_auto"
local user_file_content_mode = meta.file_content_mode

-- This will have the `file_content_mode.search_replace_auto = true` or `file_content_mode.whole = true`
local file_content_mode = {}
-- If user gives it, then, we use what we set
if user_file_content_mode then
  if user_file_content_mode == "whole" then
    file_content_mode.whole = true
  elseif user_file_content_mode == "search_replace_auto" then
    file_content_mode.search_replace_auto = true
  elseif user_file_content_mode == "udiffx" then
      file_content_mode.udiffx = true    
  else
    return aip.flow.skip("Error file_conent_mode value '" .. user_file_content_mode .. "' is invalid.\nCan be 'whole' or 'search_replace_auto'" )
  end 
-- if user does not give anything, base on write_mode
else
  -- Default: 
  -- udiffx (for new AIPack >= 0.8.12)
  if aip.udiffx then 
  	file_content_mode.udiffx = true
  -- search_replace_auto (for older AIPack without udiffx  AIPack <= 0.8.12)
  else
  	file_content_mode.search_replace_auto = true  
  end
end

-- If write_mode = true, then, turn the file_content_mode to false
if write_mode == false then
    file_content_mode.search_replace_auto = false
    file_content_mode.whole = false
end

-- === Seed the file_content_mode.prompt
local templates_dir = CTX.AGENT_FILE_DIR .. "/templates"
if file_content_mode.whole then
    local tmpl = p_tmpl.load_template("file-content-whole.md")
    instructions.file_content_change = tmpl.content
elseif file_content_mode.search_replace_auto then
    local tmpl = p_tmpl.load_template("file-content-search-replace-auto.md")
    instructions.file_content_change = tmpl.content
elseif file_content_mode.udiffx then
    local tmpl = p_tmpl.load_template("file-content-udiffx.md")
    instructions.file_content_change = tmpl.content    
end

-- === Suggest Commit
-- default true
local suggest_git_commit = false
if meta.suggest_git_commit ~= nil then
  -- if defined by user, then, take precedence
  suggest_git_commit = meta.suggest_git_commit 
else 
  -- By default suggest when write_mode is true
  suggest_git_commit = write_mode
end

if suggest_git_commit then
	local suggest_commit_content = p_tmpl.load_template("suggest-commit.md").content
  instructions.suggest_commit = suggest_commit_content
end

-- === Build the input base
local input_base = {
	  instructions                 = instructions,
    attachments                  = attachments,
    max_files_size_kb            = max_files_size_kb,
    write_mode                   = write_mode,
    file_content_mode            = file_content_mode,
    prompt_file_rel_path         = prompt_file_rel_path,
    default_language             = meta.default_language or "Python",
    knowledge_refs               = knowledge_refs,
    first_part                   = first_part,
    include_second_part          = include_second_part,
    second_part                  = second_part,
    prompt_path                  = prompt_file.path,
    inst                         = inst,
    knowledge_refs               = knowledge_refs,
    base_dir                     = base_dir,
    structure_refs               = structure_refs,
    context_refs                 = context_refs,
    prompt_files_path            = prompt_files_path,
    -- prompt explicit caching
    cache_pre_prompts            = cache_pre_prompts,
    cache_knowledge_files        = cache_knowledge_files,
    cache_context_files          = cache_context_files,
    -- output files
    ai_responses_for_raw_path    = ai_responses_for_raw_path,
    ai_responses_for_prompt_path = ai_responses_for_prompt_path,
    last_file_change_fails_report_path  = last_file_change_fails_report_path,
}

-- === Preps the inputs
local inputs = {}

-- === working_refs
-- If we have working_refs, then, we split input per working_refs (i.e., files)
if working_refs_list ~= nil and #working_refs_list > 0 then
    -- IMPORTANT - NOW IGNORE (working_concurrency)
    for _, working_refs in ipairs(working_refs_list) do
        -- Note: We put the working_file into an array for later, to allow having one input to be multiple files
        if #working_refs > 0 then
            local msg = working_refs[1].path
            if #working_refs > 1 then
                msg = msg .. ", plus " .. (#working_refs - 1) .. " files"
            end
            local _display = "working files (" .. #working_refs .."): " .. msg .. "\n\n" .. inst
            table.insert(inputs, {base = input_base, working_refs = working_refs , _display = _display})        
        end
    end    

else
    inputs = { {base = input_base, _display = inst} }
end

-- === Print Run Info
local context_file_count   = input_base.context_refs and #input_base.context_refs or 0
context_file_count = tostring(context_file_count) -- string.format("%-" .. 5 .. "s", context_file_count)
local write_mode_fmt = tostring(write_mode)
local working_group_count   = working_refs_list and #working_refs_list or 0
local knowledge_file_count = input_base.knowledge_refs and #input_base.knowledge_refs or 0
local concurrency_fmt    = "1"
if working_refs_list and #working_refs_list > 0 then
    concurrency_fmt = tostring(meta.input_concurrency)
end
concurrency_fmt = tostring(concurrency_fmt)

local run_info = "Context Files: " .. context_file_count .. " | Working Groups: " .. working_group_count .. " | Knowledge Files: " .. knowledge_file_count
run_info     =  run_info .. "\n(Write Mode: " .. write_mode_fmt .. ", Concurrency: " .. concurrency_fmt .. ")"
print(run_info)


-- === Compute the agent options
options.model             = meta.model
options.temperature       = meta.temperature
options.model_aliases     = meta.model_aliases
options.input_concurrency = meta.input_concurrency

-- NOTE: for now, it is just one input, but the goal is to allow multiple inputs
return aip.flow.before_all_response({
    inputs  = inputs,
    options = options
})

```

# Data

```lua
local p_utils  = require("prompt_utils")

-- This is the input format (.base, and the .working_refs)
local base, working_refs = input.base, input.working_refs

-- Compute new_context_refs
local new_context_refs = nil 
if working_refs and #working_refs > 1 then
    local working_set = {}
    for _, ref in ipairs(working_refs) do
        working_set[ref.path] = true
    end

    new_context_refs = {}
    for _, ref in ipairs(base.context_refs) do
        if not working_set[ref.path] then
            table.insert(new_context_refs, ref)
        end
    end
else 
    new_context_refs = base.context_refs -- by default
end


-- Compute total size
local total_size = 0
local all_refs  = {
  base.knowledge_refs or {}, -- making sure it is not nil, otherwise, loop below stops
  new_context_refs or {},
  working_refs or {}
}

for _, file_list in ipairs(all_refs) do
  for _, file in ipairs(file_list) do
    total_size = total_size + file.size
  end
end

-- Check that not more than max
local max_files_size_b = base.max_files_size_kb * 1000
if total_size > max_files_size_b then
    local msg = "Max files size reached."
    msg = msg .. "\n Actual size: " .. aip.text.format_size(total_size)
    msg = msg .. "\n    Max size: " .. aip.text.format_size(max_files_size_b)
    return aip.flow.skip(msg)
end

-- extract attachments (nil if empty or undefined)
local attachments = nil
if base.attachments and #base.attachments > 0 then
  attachments = base.attachments
end

-- Save the prompt_files_path
local prompt_files_content = "====\n\n"
if attachments then
    prompt_files_content = prompt_files_content .. "# Attachments" .. "\n"
    for _, att in ipairs(attachments) do
        prompt_files_content = prompt_files_content .. "\n- " .. att.file_source
    end
    prompt_files_content = prompt_files_content .. "\n\n"
end
prompt_files_content = prompt_files_content .. "# Knowledge Files" .. "\n\n" .. p_utils.file_refs_to_md(base.knowledge_refs) .. "\n\n"
prompt_files_content = prompt_files_content .. "# Context Files"   .. "\n\n" .. p_utils.file_refs_to_md(new_context_refs) .. "\n\n"
prompt_files_content = prompt_files_content .. "# Working Files"   .. "\n\n" .. p_utils.file_refs_to_md(working_refs) .. "\n\n"
prompt_files_content = prompt_files_content .. "# Struture Files"  .. "\n\n" .. p_utils.file_refs_to_md(base.structure_refs, "(Only file paths, not their content)") .. "\n\n"
aip.file.append(base.prompt_files_path, prompt_files_content)


-- Augment the base
base.knowledge_files = p_utils.load_file_refs(CTX.WORKSPACE_DIR, base.knowledge_refs)
base.context_files   = p_utils.load_file_refs(base.base_dir, new_context_refs)
base.working_files   = p_utils.load_file_refs(base.base_dir, working_refs)

-- Add time if available
if aip.time.weekday_local and aip.time.now_iso_local then
    base.now_local = aip.time.now_iso_local() .. " (" .. aip.time.weekday_local() .. ")"
end
-- Print info
local knowledge_file_count = tostring(base.knowledge_files and #base.knowledge_files or 0)
local working_file_count = tostring(base.working_files and #base.working_files or 0)
local context_file_count = tostring(base.context_files and #base.context_files or 0)
local task_info = "Context Files: " .. context_file_count .. " | Working Files: " .. working_file_count .. " | Knowledge Files: " .. knowledge_file_count
if attachments then
    task_info = task_info .. " | Attachments: " .. #attachments
end
-- Disable, because now it won't include the attachments size
-- if total_size > 0 then
--     local total_size_fmt = aip.text.format_size(total_size, {trim = true})
--     task_info = task_info .. "\nTotal files size: " .. total_size_fmt
-- end
if base.now_local then
   task_info = task_info .. "\nTime: " .. base.now_local
end
print(task_info)



-- The augmented base becomes the data.
return aip.flow.data_response({
    data        = base,
    attachments = base.attachments,
})
```

# System `cache = {{data.cache_pre_prompts}}`

You are a senior developer expert who has deep expertise in many languages and creates production-grade quality code (simple and scalable).

The user instruction will ask you to review/update the existing code or create new code if no existing code is provided.

When the language cannot be inferred from the user or context provided, assume the question is for the {{data.default_language}}` programming language. Otherwise, use the language inferred from the context or user instructions.

When you generate markdown, make sure to leave one empty line before and after any heading, except if the heading is the first line of the file.


When existing code, do not perform reformatting or make unnecessary changes unless explicitly requested by the user or specified in the user/system knowledge or instructions.

When providing text or comments, do not use em dash (—) as a sentence part seprator, use a comma, semi-column, or period as appropriate. Do not use dashes as sentence separators, never.

# User

{{#if data.write_mode}}

When giving code back that needs to creating or modify files, make sure to follow the `## AIP File Change format convention instructions` instruction below.

## Basic AIP File Change format convention instructions

All file change, create or update should be of the following format. 

- Inside a `AIP_FILE_CHANGE` tag
- With a `file_path="..."` file path attribute
- And the content of the file inside, surrounded by the four backticks and the language

For example: 

<AIP_FILE_CHANGE file_path="path/to/file.ts">
````ts
CHANGE_CONTENT_HERE
````
</AIP_FILE_CHANGE>
{{/if}}


# User `cache = {{data.cache_pre_prompts}}`

{{#if data.instructions.file_content_change}}
{{data.instructions.file_content_change}}
{{/if}}

# User `cache = {{data.cache_pre_prompts}}`

Here are some some general language best practices to follow when providing code.

## Languages best practices

### HTML

- Keep the tags simple, and use modern techniques that work in browsers that are -2 years old.
- Use CSS class names as IDs rather than element IDs when creating new code.
    - However, do not change the code unless explicitly asked by the user.

### JavaScript

- Use the web module loading so that we can use modern JavaScript.
- When drawing, try to use Canvas 2D.
- Use standard fetch to retrieve JSON.

### CSS

- Try to use CSS Grid when possible.
- When files are `.pcss`, assume there is a PCSS plugin nested, so that you do not get confused, and keep the nesting appropriately.

### General

- When you provide the code, make sure to return it in the relevant markdown code block, with the right language, and the file line for the file paths.
- Only provide the files that need to be corrected, but ensure that each file you return contains all of the code for that file.
- Ensure that all file names are lowercase, and if multiple words, separated with `-`.
- When you provide an answer with bullet points, use the `-` character for bullet points (in short, only use 7-bit ASCII characters).
- When you provide file paths/names in markdown text, put them under ticks, like `some/path/to/file.rs`.
- Do not remove code regions except if explicitly asked.

# User `cache = {{data.cache_pre_prompts}}`

{{#if data.instructions.suggest_commit}}
{{data.instructions.suggest_commit}}
{{/if}}

When ask to update some files, if you do not have have some files that you should have, answer the missing files under a `<missing_files>` tag like for example: 

<missing_files>
<mf_message>
HERE_THE_MESSAGE_TO_THE_USER
</mf_message>
<mf_files>
  - FILE_PATH
  - FILE_PATH
  - ...
</mf_files>
</missing_files>

Note that sometime, the user will ask to create new files, so, that's ok, you can create them. 

# User `cache = {{data.cache_knowledge_files}}`

{{#if data.knowledge_files}}

Here are some important knowledge, guidelines, and best practices I like you to follow. Make sure you respect them when providing code. Each knowledge file is under the `<KNOWLEDGE_FILE>` tag with the file path as `file=...`

{{#each data.knowledge_files}}

<KNOWLEDGE_FILE file_path="{{this.path}}">
````{{this.ext}}
{{this.content}}
````
</KNOWLEDGE_FILE>

{{/each}}

{{/if}}

# User `cache = false`

{{#if data.structure_refs}}

Here are the file structure of this project. Do not edit/change file you do not have source for. 
Those are for your reference, in case there are referred somewhere. 

{{#each data.structure_refs}}
- {{this.path}}
{{/each}}

{{/if}}


# User `cache = {{data.cache_context_files}}`

{{#if data.context_files}}

Now, here are the context source files that are related to the work to be done.

{{#each data.context_files}}

<CONTEXT_FILE file_path="{{this.path}}">
````{{this.ext}}
{{this.content}}
````
</CONTEXT_FILE>

{{/each}}

Only write the files that need to be rewritten based on the user instruction.

{{/if}}

# User

{{#if data.working_files}}

Here is the working files you need to work on.

{{#each data.working_files}}
<WORKING_FILE file_path="{{this.path}}">
````{{this.ext}}
{{this.content}}
````
</WORKING_FILE>

{{/each}}

Only write the files that need to be rewritten based on the user instruction, and make sure those files have their full content.

{{/if}}

# User

{{#if data.include_second_part}}

User's content and/or previous answer.

Here is some context and/or your previous answer:

{{data.second_part}}

{{/if}}

# User

{{#if data.inst}}
Here are my instruction for this work:

{{data.inst}}

{{/if}}

{{#if data.now_local}}
Here is today local date / time if user ask to do something with it: 
{{data.now_local}}
{{/if}}

**Important additional instruction:**

- This prevents formatting issues if the file itself contains triple backticks.
- **Never remove or alter existing comments. (except if explictly asked by the user)**  
  Comments must be preserved *verbatim*, including spacing, indentation, and placement, even if they appear redundant or outdated.
- Do **not** add trivial explanatory comments (e.g., explaining imports, renames, or obvious changes).  
  Only add comments that provide meaningful context, design rationale, or structure (such as region markers or explanations of non-obvious logic).
- **Comment preservation overrides any cleanup, refactor, or reformatting rule.**



# Output

```lua
local o_utils = require("output_utils")

local base_dir = data.base_dir

local ai_content = ai_response.content

-- By default, the second part is the ai_content
local second_part = ai_content

-- Info lines
local info_lines = o_utils.build_info_lines(ai_response, data)

-- === Write to the ai_content_for_raw
local ai_content_for_raw = "====\n" .. info_lines .. "\n\n" .. ai_content .. "\n\n"
aip.file.append(data.ai_responses_for_raw_path, ai_content_for_raw)

-- === Write to the src file
local files_changes_failed = {} -- [{path, changes_info}]
local files_changed = {}
if data.write_mode == true then
		if data.file_content_mode.udiffx then
			local changes_status, other_content = aip.udiffx.apply_file_changes(ai_content, base_dir, {extrude = "content"} )
			second_part = other_content
			if changes_status.items then
				for _, item in ipairs(changes_status.items) do
				local f_path = aip.path.join(base_dir, item.file_path)
				if item.success then
						table.insert(files_changed, f_path)
					else
						table.insert(files_changes_failed, {
							path = f_path,
							changes_info = {
								failed_changes = { { reason = item.error_msg or "Unknown error", search = "UDIFFX Block failed (see '.cache/last_ai_responses_for_raw.md'" } }
							}
						})
					end
				end
			elseif changes_status.error then
				print("Error applying udiffx: " .. changes_status.error)
			end
		else 
	    local elems, other_content = aip.tag.extract(ai_content, {"AIP_FILE_CHANGE"}, {extrude = "content"})
	    -- In this case, the other_content becomes the second_part
	    second_part = other_content
	    for _, elem in ipairs(elems) do
	        local file_path = elem.attrs and elem.attrs.file_path
	
	        local file_change_content = aip.md.outer_block_content_or_raw(aip.text.trim(elem.content))
	        if file_path then
	            file_path = aip.path.join(base_dir, file_path)
	            if data.file_content_mode.search_replace_auto then 
	                local file_changed, changes_info = aip.file.save_changes(file_path, file_change_content)
	                if changes_info and changes_info.failed_changes then
	                   table.insert(files_changes_failed, {path = file_path, changes_info = changes_info})
	                end
	            else
	                aip.file.save(file_path, file_change_content)
	            end
	            table.insert(files_changed, file_path)
	        else 
	            -- NOTE: For now, we just concatenate back this block at the send of the second_part
	            -- TODO: Later, we will extract_blocks extrude = segments (when supported) to rebuild the proper order
	            local md_block_raw = "````" .. (block.lang or "") .. "\n" .. block.content .. "````"
	
	            second_part = second_part .. "\n" .. md_block_raw
	        end
	
	        ::continue::
	    end -- for 
		end -- else of if data.file_content_mode.udiffx
end

-- === Process files_changes_failed
if #files_changes_failed > 0 then 
    local ai_res_path =  aip.path.diff(data.ai_responses_for_raw_path, CTX.WORKSPACE_DIR)
    local fail_report_path =  aip.path.diff(data.last_file_change_fails_report_path, CTX.WORKSPACE_DIR)

    local fail_report_content = "❗ Here are the file change search misses.\nSee full AI response at:\n" .. ai_res_path

    fail_report_content = fail_report_content .. "\n\n" .. "Below are the search misses by file:"

    local msg = "❗❗❗ Failed to apply some changes to file(s) ❗❗❗\n"
    for _, fc in ipairs(files_changes_failed) do
        -- NOTE: for now, just show the first reason
        msg = msg .. "\n- " .. fc.path .. " (failed changes: " .. #fc.changes_info.failed_changes .. ", cause: " .. fc.changes_info.failed_changes[1].reason .. ")"

        fail_report_content = fail_report_content .. "\n\n# " .. fc.path .. "\n\nFailed searches:"
        for _, fail_change in ipairs(fc.changes_info.failed_changes) do
            fail_report_content = fail_report_content .. "\n\n````\n" .. fail_change.search .. "\n````"
        end
    end
    local ai_responses_for_raw_rel_path = aip.path.diff(data.ai_responses_for_raw_path, CTX.WORKSPACE_DIR)

    msg = msg .. "\n\nFor fail report, see file:\n➜ " .. fail_report_path

    msg = msg .. "\n\nFor full raw AI response, see file:\n➜ " .. ai_responses_for_raw_rel_path 

    aip.task.pin("changes_failed", 0, {label = "WARNING", content = msg})

    aip.file.append(data.last_file_change_fails_report_path, fail_report_content .. "\n\n")
end

-- === Process the eventual content to pin/print
o_utils.process_ui_directives(second_part)

-- === Append to the second_part to ai_content_for_prompt file
second_part = aip.text.trim_start(second_part)
local ai_content_for_prompt = "====\n" .. info_lines .. "\n\n" .. second_part .. "\n"
aip.file.append(data.ai_responses_for_prompt_path, ai_content_for_prompt)

-- === Update the prompt file
local first_part = aip.text.trim_end(data.first_part)

local ai_content_for_prompt = aip.file.load(data.ai_responses_for_prompt_path).content
local prompt_content = first_part .. "\n\n" .. ai_content_for_prompt

aip.file.save(data.prompt_path, prompt_content)

-- print("Executed from your @coder prompt file:" .. data.prompt_file_rel_path)

-- === Build the Response
local response = "✅ pro@coder task done.\n"

if data.write_mode then
    if #files_changed == 0 then
        response = response .. "\nNo File changed."
        response = response .. "\nCheck prompt file for more AI answer."
        response = response .. "\nPrompt file:\n→ " .. data.prompt_file_rel_path        
    else 
        local file_txt = "file"
        if #files_changed > 1 then
            file_txt = "files"
        end
        response = response .. "\n" .. #files_changed .. " " .. file_txt .. " changed:\n"
        response = response .. "→ " .. table.concat(files_changed, "\n→ ")
        response = response .. "\n\nCheck prompt file for more AI answer. Prompt file:"
        response = response .. "\n→ " .. data.prompt_file_rel_path        
    end
else 
    response = response .. "\nPrompt File has been updated with AI Response. Prompt file:"
    response = response .. "\n→ " .. data.prompt_file_rel_path
end

return response
```
